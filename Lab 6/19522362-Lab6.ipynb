{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "+ Nguyễn Đức Toàn - 19522362\n",
        "\n",
        "+ Link Github: https://github.com/tndTool/DataMining.git"
      ],
      "metadata": {
        "id": "Ln18GevVCPtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Feature Engineering**\n",
        "\n"
      ],
      "metadata": {
        "id": "vjLRhib_gBG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/elonmusk_tweets.csv')\n",
        "print(len(data))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "yEFKLUl2oWi6",
        "outputId": "1ffebe45-20c5-4fde-a419-91dfe03b5215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2819\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   id           created_at  \\\n",
              "0  849636868052275200  2017-04-05 14:56:29   \n",
              "1  848988730585096192  2017-04-03 20:01:01   \n",
              "2  848943072423497728  2017-04-03 16:59:35   \n",
              "3  848935705057280001  2017-04-03 16:30:19   \n",
              "4  848416049573658624  2017-04-02 06:05:23   \n",
              "\n",
              "                                                text  \n",
              "0  b'And so the robots spared humanity ... https:...  \n",
              "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...  \n",
              "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'  \n",
              "3                b'Stormy weather in Shortville ...'  \n",
              "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b52a3f54-b3de-4b18-8661-a73ca437c58f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>849636868052275200</td>\n",
              "      <td>2017-04-05 14:56:29</td>\n",
              "      <td>b'And so the robots spared humanity ... https:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>848988730585096192</td>\n",
              "      <td>2017-04-03 20:01:01</td>\n",
              "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>848943072423497728</td>\n",
              "      <td>2017-04-03 16:59:35</td>\n",
              "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>848935705057280001</td>\n",
              "      <td>2017-04-03 16:30:19</td>\n",
              "      <td>b'Stormy weather in Shortville ...'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>848416049573658624</td>\n",
              "      <td>2017-04-02 06:05:23</td>\n",
              "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52a3f54-b3de-4b18-8661-a73ca437c58f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b52a3f54-b3de-4b18-8661-a73ca437c58f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b52a3f54-b3de-4b18-8661-a73ca437c58f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Text Normalization"
      ],
      "metadata": {
        "id": "Gx97VZmWgHOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')\n",
        "import pprint \n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "metadata": {
        "id": "RJtYGIshgFFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72a17b2-fd97-4704-b639-9126b1b22b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(document):\n",
        "    # TODO: remove punctuation\n",
        "    text = \"\".join([ch for ch in document if ch not in string.punctuation])\n",
        "    \n",
        "    # TODO: tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    \n",
        "    # TODO: Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    ret = \" \".join([stemmer.stem(word.lower()) for word in tokens])\n",
        "    return ret\n",
        "\n",
        "original_documents = [x.strip() for x in data['text']] \n",
        "documents = [normalize(d).split() for d in original_documents]\n",
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W50pPAqyodm9",
        "outputId": "96273872-06cf-4e49-bb92-7e8236d2b774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['band', 'so', 'the', 'robot', 'spare', 'human', 'httpstcov7jujqwfcv']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Implement TF-IDF "
      ],
      "metadata": {
        "id": "TgfZpI2QgJ1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten all the documents\n",
        "flat_list = [word for doc in documents for word in doc]\n",
        "\n",
        "# TODO: remove stop words from the vocabulary\n",
        "words = [word for word in flat_list if word not in stopwords.words('english')]\n",
        "\n",
        "# TODO: we take the 500 most common words only\n",
        "counts = Counter(words)\n",
        "vocabulary = counts.most_common(500)\n",
        "print([x for x in vocabulary if x[0] == 'tesla'])\n",
        "vocabulary = [x[0] for x in vocabulary]\n",
        "assert len(vocabulary) == 500\n",
        "\n",
        "# vocabulary.sort()\n",
        "vocabulary[:5]"
      ],
      "metadata": {
        "id": "aakQK-zugKk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6882371e-7c9a-44d9-ee6c-982cfbb00cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tesla', 287)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['brt', 'tesla', 'spacex', 'model', 'thi']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf(vocabulary, documents):\n",
        "    matrix = [0] * len(documents)\n",
        "    for i, document in enumerate(documents):\n",
        "        counts = Counter(document)\n",
        "        matrix[i] = [0] * len(vocabulary)\n",
        "        for j, term in enumerate(vocabulary):\n",
        "            matrix[i][j] = counts[term]\n",
        "    return matrix\n",
        "\n",
        "tf = tf(vocabulary, documents)\n",
        "np.array(vocabulary)[np.where(np.array(tf[1]) > 0)], np.array(tf[1])[np.where(np.array(tf[1]) > 0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJsaqEM1oldM",
        "outputId": "cbd7db8f-0ae0-4143-c8c7-ba185f5ae675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['tesla', 'exactli'], dtype='<U17'), array([1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def idf(vocabulary, documents):\n",
        "    \"\"\"TODO: compute IDF, storing values in a dictionary\"\"\"\n",
        "    idf = {}\n",
        "    num_documents = len(documents)\n",
        "    for i, term in enumerate(vocabulary):\n",
        "            idf[term] = math.log(num_documents / sum(term in document for document in documents), 2)\n",
        "    return idf\n",
        "\n",
        "idf = idf(vocabulary, documents)\n",
        "[idf[key] for key in vocabulary[:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggh9OydLomts",
        "outputId": "7c938882-a1ee-4216-802d-b1310c88f1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.539126825495932,\n",
              " 3.3163095197385393,\n",
              " 3.7262581423445837,\n",
              " 3.8171115727956972,\n",
              " 3.8027562798186274]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(document, vocabulary, idf):\n",
        "    vector = [0]*len(vocabulary)\n",
        "    counts = Counter(document)\n",
        "    for i,term in enumerate(vocabulary):\n",
        "        vector[i] = idf[term] * counts[term]\n",
        "    return vector\n",
        "\n",
        "document_vectors = [vectorize(s, vocabulary, idf) for s in documents]\n",
        "np.array(vocabulary)[np.where(np.array(document_vectors[1]) > 0)], np.array(document_vectors[1])[np.where(np.array(document_vectors[1]) > 0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5rBwrx0oqi9",
        "outputId": "b71f1d82-cbd8-4b15-c298-e243b2362e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['tesla', 'exactli'], dtype='<U17'), array([3.31630952, 6.65361284]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compare the results with the reference implementation of scikit-learn library. "
      ],
      "metadata": {
        "id": "kzhT3odAgK72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english', max_features=500)\n",
        "\n",
        "features = tfidf.fit(original_documents)\n",
        "corpus_tf_idf = tfidf.transform(original_documents) \n",
        "\n",
        "sum_words = corpus_tf_idf.sum(axis=0)\n",
        "words_freq = [(word, sum_words[0, idx]) for word, idx in tfidf.vocabulary_.items()]\n",
        "print(sorted(words_freq, key = lambda x: x[1], reverse=True)[:5])\n",
        "print('testla', corpus_tf_idf[1, features.vocabulary_['tesla']])"
      ],
      "metadata": {
        "id": "UFwy47CdgM5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86998c1-d364-4654-93bf-2406482c846e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('http', 163.54366542841234), ('https', 151.85039944652075), ('rt', 112.61998731390989), ('tesla', 95.96401470715628), ('xe2', 88.20944486346477)]\n",
            "testla 0.3495243100660956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Apply TF-IDF for information retrieval"
      ],
      "metadata": {
        "id": "hnvfejQygOMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1,v2):\n",
        "    \"\"\"TODO: compute cosine similarity\"\"\"\n",
        "    sumxx, sumxy, sumyy = 0, 0, 0\n",
        "    for i in range(len(v1)):\n",
        "        x = v1[i]; y = v2[i]\n",
        "        sumxx += x*x\n",
        "        sumyy += y*y\n",
        "        sumxy += x*y\n",
        "    if sumxy == 0:\n",
        "            result = 0\n",
        "    else:\n",
        "            result = sumxy/math.sqrt(sumxx*sumyy)\n",
        "    return result\n",
        "\n",
        "def search_vec(query, k, vocabulary, stemmer, document_vectors, original_documents):\n",
        "    q = query.split()\n",
        "    q = [stemmer.stem(w) for w in q]\n",
        "    query_vector = vectorize(q, vocabulary, idf)\n",
        "    \n",
        "    # TODO: rank the documents by cosine similarity\n",
        "    scores = [[cosine_similarity(query_vector, document_vectors[d]), d] for d in range(len(document_vectors))]\n",
        "    scores.sort(key=lambda x: -x[0])\n",
        "    \n",
        "    print('Top-{0} documents'.format(k))\n",
        "    for i in range(k):\n",
        "        print(i, original_documents[scores[i][1]])\n",
        "\n",
        "query = \"tesla nasa\"\n",
        "stemmer = PorterStemmer()\n",
        "search_vec(query, 5, vocabulary, stemmer, document_vectors, original_documents)"
      ],
      "metadata": {
        "id": "BHuHIBd5gPK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52110bde-6ea5-4f80-c25c-272b6489bab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 documents\n",
            "0 b'@ashwin7002 @NASA @faa @AFPAA We have not ruled that out.'\n",
            "1 b'RT @NASA: Updated @SpaceX #Dragon #ISS rendezvous times: NASA TV coverage begins Sunday at 3:30amET: http://t.co/qrm0Dz4jPE. Grapple at  ...'\n",
            "2 b\"Deeply appreciate @NASA's faith in @SpaceX. We will do whatever it takes to make NASA and the American people proud.\"\n",
            "3 b'Would also like to congratulate @Boeing, fellow winner of the @NASA commercial crew program'\n",
            "4 b\"@astrostephenson We're aiming for late 2015, but NASA needs to have overlapping capability to be safe. Would do the same\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_features = tfidf.transform([query])\n",
        "\n",
        "cosine_similarities = linear_kernel(new_features, corpus_tf_idf).flatten()\n",
        "related_docs_indices = cosine_similarities.argsort()[::-1]\n",
        "\n",
        "topk = 5\n",
        "print('Top-{0} documents'.format(topk))\n",
        "for i in range(topk):\n",
        "    print(i, original_documents[related_docs_indices[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js5Da-mToxpm",
        "outputId": "2a803a8f-2744-45a1-b649-27c1897f731b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 documents\n",
            "0 b'@ashwin7002 @NASA @faa @AFPAA We have not ruled that out.'\n",
            "1 b\"SpaceX could not do this without NASA. Can't express enough appreciation. https://t.co/uQpI60zAV7\"\n",
            "2 b'@NASA launched a rocket into the northern lights http://t.co/tR2cSeMV'\n",
            "3 b'Whatever happens today, we could not have done it without @NASA, but errors are ours alone and me most of all.'\n",
            "4 b'RT @NASA: Updated @SpaceX #Dragon #ISS rendezvous times: NASA TV coverage begins Sunday at 3:30amET: http://t.co/qrm0Dz4jPE. Grapple at  ...'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. Text Processing**"
      ],
      "metadata": {
        "id": "Pg9Hk_0XgRmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Preprocessing "
      ],
      "metadata": {
        "id": "0CyphcR3gSzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NLTK and all the needed libraries\n",
        "import nltk\n",
        "nltk.download('punkt') #Run this line one time to get the resource\n",
        "nltk.download('stopwords') #Run this line one time to get the resource\n",
        "nltk.download('wordnet') #Run this line one time to get the resource\n",
        "nltk.download('averaged_perceptron_tagger') #Run this line one time to get the resource\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1gSTdR2FgTMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00864074-e117-4dab-94c0-ae32c58dc635"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/coldplay.csv')\n",
        "print(len(data))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "FF4JXOPYXpeN",
        "outputId": "a24bb2cb-3ed8-4f03-adb2-6dfa4874ca7b"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Artist                           Song  \\\n",
              "0  Coldplay                 Another's Arms   \n",
              "1  Coldplay                Bigger Stronger   \n",
              "2  Coldplay                       Daylight   \n",
              "3  Coldplay                       Everglow   \n",
              "4  Coldplay  Every Teardrop Is A Waterfall   \n",
              "\n",
              "                                                Link  \\\n",
              "0            /c/coldplay/anothers+arms_21079526.html   \n",
              "1          /c/coldplay/bigger+stronger_20032648.html   \n",
              "2                 /c/coldplay/daylight_20032625.html   \n",
              "3                 /c/coldplay/everglow_21104546.html   \n",
              "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
              "\n",
              "                                              Lyrics  \n",
              "0  Late night watching tv  \\nUsed to be you here ...  \n",
              "1  I want to be bigger stronger drive a faster ca...  \n",
              "2  To my surprise, and my delight  \\nI saw sunris...  \n",
              "3  Oh, they say people come  \\nThey say people go...  \n",
              "4  I turn the music up, I got my records on  \\nI ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e47bbbc9-5fa9-4703-affc-53f837495d5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>Link</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Another's Arms</td>\n",
              "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
              "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Bigger Stronger</td>\n",
              "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
              "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Daylight</td>\n",
              "      <td>/c/coldplay/daylight_20032625.html</td>\n",
              "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Everglow</td>\n",
              "      <td>/c/coldplay/everglow_21104546.html</td>\n",
              "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Every Teardrop Is A Waterfall</td>\n",
              "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
              "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e47bbbc9-5fa9-4703-affc-53f837495d5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e47bbbc9-5fa9-4703-affc-53f837495d5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e47bbbc9-5fa9-4703-affc-53f837495d5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb7zCp1-Xv8t",
        "outputId": "e11fe99b-b9e0-4cca-ae8e-540c4c0b02ce"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Artist  120 non-null    object\n",
            " 1   Song    120 non-null    object\n",
            " 2   Link    120 non-null    object\n",
            " 3   Lyrics  120 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 3.9+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Select the song 'Every Teardrop Is A Waterfall'\n",
        "song = data[data['Song'] == 'Every Teardrop Is A Waterfall']['Lyrics'].values[0]\n",
        "song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "WurBPovrYsi2",
        "outputId": "9c7fdac1-a28d-4624-febc-6d0aceddb1ff"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I turn the music up, I got my records on  \\nI shut the world outside until the lights come on  \\nMaybe the streets alight, maybe the trees are gone  \\nI feel my heart start beating to my favourite song  \\n  \\nAnd all the kids they dance, all the kids all night  \\nUntil Monday morning feels another life  \\nI turn the music up  \\nI'm on a roll this time  \\nAnd heaven is in sight  \\n  \\nI turn the music up, I got my records on  \\nFrom underneath the rubble sing a rebel song  \\nDon't want to see another generation drop  \\nI'd rather be a comma than a full stop  \\n  \\nMaybe I'm in the black, maybe I'm on my knees  \\nMaybe I'm in the gap between the two trapezes  \\nBut my heart is beating and my pulses start  \\nCathedrals in my heart  \\n  \\nAs we saw oh this light I swear you, emerge blinking into  \\nTo tell me it's alright  \\nAs we soar walls, every siren is a symphony  \\nAnd every tear's a waterfall  \\nIs a waterfall  \\nOh  \\nIs a waterfall  \\nOh oh oh  \\nIs a is a waterfall  \\nEvery tear  \\nIs a waterfall  \\nOh oh oh  \\n  \\nSo you can hurt, hurt me bad  \\nBut still I'll raise the flag  \\n  \\nOh  \\nIt was a wa wa wa wa wa-aterfall  \\nA wa wa wa wa wa-aterfall  \\n  \\nEvery tear  \\nEvery tear  \\nEvery teardrop is a waterfall  \\n  \\nEvery tear  \\nEvery tear  \\nEvery teardrop is a waterfall  \\n  \\nEvery tear  \\nEvery tear  \\nEvery teardrop is a waterfall\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Tokenize the lyrics of the song and save the tokens into a variable and print it\n",
        "tokens = word_tokenize(song)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J8ZifjzY3fN",
        "outputId": "a85e723a-0ab2-447c-bcc2-4bfa7470f84e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " ',',\n",
              " 'I',\n",
              " 'got',\n",
              " 'my',\n",
              " 'records',\n",
              " 'on',\n",
              " 'I',\n",
              " 'shut',\n",
              " 'the',\n",
              " 'world',\n",
              " 'outside',\n",
              " 'until',\n",
              " 'the',\n",
              " 'lights',\n",
              " 'come',\n",
              " 'on',\n",
              " 'Maybe',\n",
              " 'the',\n",
              " 'streets',\n",
              " 'alight',\n",
              " ',',\n",
              " 'maybe',\n",
              " 'the',\n",
              " 'trees',\n",
              " 'are',\n",
              " 'gone',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'start',\n",
              " 'beating',\n",
              " 'to',\n",
              " 'my',\n",
              " 'favourite',\n",
              " 'song',\n",
              " 'And',\n",
              " 'all',\n",
              " 'the',\n",
              " 'kids',\n",
              " 'they',\n",
              " 'dance',\n",
              " ',',\n",
              " 'all',\n",
              " 'the',\n",
              " 'kids',\n",
              " 'all',\n",
              " 'night',\n",
              " 'Until',\n",
              " 'Monday',\n",
              " 'morning',\n",
              " 'feels',\n",
              " 'another',\n",
              " 'life',\n",
              " 'I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'a',\n",
              " 'roll',\n",
              " 'this',\n",
              " 'time',\n",
              " 'And',\n",
              " 'heaven',\n",
              " 'is',\n",
              " 'in',\n",
              " 'sight',\n",
              " 'I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " ',',\n",
              " 'I',\n",
              " 'got',\n",
              " 'my',\n",
              " 'records',\n",
              " 'on',\n",
              " 'From',\n",
              " 'underneath',\n",
              " 'the',\n",
              " 'rubble',\n",
              " 'sing',\n",
              " 'a',\n",
              " 'rebel',\n",
              " 'song',\n",
              " 'Do',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'to',\n",
              " 'see',\n",
              " 'another',\n",
              " 'generation',\n",
              " 'drop',\n",
              " 'I',\n",
              " \"'d\",\n",
              " 'rather',\n",
              " 'be',\n",
              " 'a',\n",
              " 'comma',\n",
              " 'than',\n",
              " 'a',\n",
              " 'full',\n",
              " 'stop',\n",
              " 'Maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'black',\n",
              " ',',\n",
              " 'maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'my',\n",
              " 'knees',\n",
              " 'Maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'gap',\n",
              " 'between',\n",
              " 'the',\n",
              " 'two',\n",
              " 'trapezes',\n",
              " 'But',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'is',\n",
              " 'beating',\n",
              " 'and',\n",
              " 'my',\n",
              " 'pulses',\n",
              " 'start',\n",
              " 'Cathedrals',\n",
              " 'in',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'As',\n",
              " 'we',\n",
              " 'saw',\n",
              " 'oh',\n",
              " 'this',\n",
              " 'light',\n",
              " 'I',\n",
              " 'swear',\n",
              " 'you',\n",
              " ',',\n",
              " 'emerge',\n",
              " 'blinking',\n",
              " 'into',\n",
              " 'To',\n",
              " 'tell',\n",
              " 'me',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'alright',\n",
              " 'As',\n",
              " 'we',\n",
              " 'soar',\n",
              " 'walls',\n",
              " ',',\n",
              " 'every',\n",
              " 'siren',\n",
              " 'is',\n",
              " 'a',\n",
              " 'symphony',\n",
              " 'And',\n",
              " 'every',\n",
              " 'tear',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'So',\n",
              " 'you',\n",
              " 'can',\n",
              " 'hurt',\n",
              " ',',\n",
              " 'hurt',\n",
              " 'me',\n",
              " 'bad',\n",
              " 'But',\n",
              " 'still',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'raise',\n",
              " 'the',\n",
              " 'flag',\n",
              " 'Oh',\n",
              " 'It',\n",
              " 'was',\n",
              " 'a',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'A',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Remove the punctuation, then save the result into a variable and print it\n",
        "tokens_no_punct = [token for token in tokens if token not in string.punctuation]\n",
        "tokens_no_punct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRrLhSNpY6YU",
        "outputId": "0614a250-a4d6-404f-e626-40ad288e2789"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " 'I',\n",
              " 'got',\n",
              " 'my',\n",
              " 'records',\n",
              " 'on',\n",
              " 'I',\n",
              " 'shut',\n",
              " 'the',\n",
              " 'world',\n",
              " 'outside',\n",
              " 'until',\n",
              " 'the',\n",
              " 'lights',\n",
              " 'come',\n",
              " 'on',\n",
              " 'Maybe',\n",
              " 'the',\n",
              " 'streets',\n",
              " 'alight',\n",
              " 'maybe',\n",
              " 'the',\n",
              " 'trees',\n",
              " 'are',\n",
              " 'gone',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'start',\n",
              " 'beating',\n",
              " 'to',\n",
              " 'my',\n",
              " 'favourite',\n",
              " 'song',\n",
              " 'And',\n",
              " 'all',\n",
              " 'the',\n",
              " 'kids',\n",
              " 'they',\n",
              " 'dance',\n",
              " 'all',\n",
              " 'the',\n",
              " 'kids',\n",
              " 'all',\n",
              " 'night',\n",
              " 'Until',\n",
              " 'Monday',\n",
              " 'morning',\n",
              " 'feels',\n",
              " 'another',\n",
              " 'life',\n",
              " 'I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'a',\n",
              " 'roll',\n",
              " 'this',\n",
              " 'time',\n",
              " 'And',\n",
              " 'heaven',\n",
              " 'is',\n",
              " 'in',\n",
              " 'sight',\n",
              " 'I',\n",
              " 'turn',\n",
              " 'the',\n",
              " 'music',\n",
              " 'up',\n",
              " 'I',\n",
              " 'got',\n",
              " 'my',\n",
              " 'records',\n",
              " 'on',\n",
              " 'From',\n",
              " 'underneath',\n",
              " 'the',\n",
              " 'rubble',\n",
              " 'sing',\n",
              " 'a',\n",
              " 'rebel',\n",
              " 'song',\n",
              " 'Do',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'to',\n",
              " 'see',\n",
              " 'another',\n",
              " 'generation',\n",
              " 'drop',\n",
              " 'I',\n",
              " \"'d\",\n",
              " 'rather',\n",
              " 'be',\n",
              " 'a',\n",
              " 'comma',\n",
              " 'than',\n",
              " 'a',\n",
              " 'full',\n",
              " 'stop',\n",
              " 'Maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'black',\n",
              " 'maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'my',\n",
              " 'knees',\n",
              " 'Maybe',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'gap',\n",
              " 'between',\n",
              " 'the',\n",
              " 'two',\n",
              " 'trapezes',\n",
              " 'But',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'is',\n",
              " 'beating',\n",
              " 'and',\n",
              " 'my',\n",
              " 'pulses',\n",
              " 'start',\n",
              " 'Cathedrals',\n",
              " 'in',\n",
              " 'my',\n",
              " 'heart',\n",
              " 'As',\n",
              " 'we',\n",
              " 'saw',\n",
              " 'oh',\n",
              " 'this',\n",
              " 'light',\n",
              " 'I',\n",
              " 'swear',\n",
              " 'you',\n",
              " 'emerge',\n",
              " 'blinking',\n",
              " 'into',\n",
              " 'To',\n",
              " 'tell',\n",
              " 'me',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'alright',\n",
              " 'As',\n",
              " 'we',\n",
              " 'soar',\n",
              " 'walls',\n",
              " 'every',\n",
              " 'siren',\n",
              " 'is',\n",
              " 'a',\n",
              " 'symphony',\n",
              " 'And',\n",
              " 'every',\n",
              " 'tear',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'So',\n",
              " 'you',\n",
              " 'can',\n",
              " 'hurt',\n",
              " 'hurt',\n",
              " 'me',\n",
              " 'bad',\n",
              " 'But',\n",
              " 'still',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'raise',\n",
              " 'the',\n",
              " 'flag',\n",
              " 'Oh',\n",
              " 'It',\n",
              " 'was',\n",
              " 'a',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'A',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'is',\n",
              " 'a',\n",
              " 'waterfall']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. remove the stop words using NLTK. Then put the result into a variable and print it\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens_no_stop_words = [token for token in tokens_no_punct if token.lower() not in stop_words]\n",
        "tokens_no_stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnPFuze2Y9Ad",
        "outputId": "dacbf4b9-3793-4650-c293-227192cda2de"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'records',\n",
              " 'shut',\n",
              " 'world',\n",
              " 'outside',\n",
              " 'lights',\n",
              " 'come',\n",
              " 'Maybe',\n",
              " 'streets',\n",
              " 'alight',\n",
              " 'maybe',\n",
              " 'trees',\n",
              " 'gone',\n",
              " 'feel',\n",
              " 'heart',\n",
              " 'start',\n",
              " 'beating',\n",
              " 'favourite',\n",
              " 'song',\n",
              " 'kids',\n",
              " 'dance',\n",
              " 'kids',\n",
              " 'night',\n",
              " 'Monday',\n",
              " 'morning',\n",
              " 'feels',\n",
              " 'another',\n",
              " 'life',\n",
              " 'turn',\n",
              " 'music',\n",
              " \"'m\",\n",
              " 'roll',\n",
              " 'time',\n",
              " 'heaven',\n",
              " 'sight',\n",
              " 'turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'records',\n",
              " 'underneath',\n",
              " 'rubble',\n",
              " 'sing',\n",
              " 'rebel',\n",
              " 'song',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'see',\n",
              " 'another',\n",
              " 'generation',\n",
              " 'drop',\n",
              " \"'d\",\n",
              " 'rather',\n",
              " 'comma',\n",
              " 'full',\n",
              " 'stop',\n",
              " 'Maybe',\n",
              " \"'m\",\n",
              " 'black',\n",
              " 'maybe',\n",
              " \"'m\",\n",
              " 'knees',\n",
              " 'Maybe',\n",
              " \"'m\",\n",
              " 'gap',\n",
              " 'two',\n",
              " 'trapezes',\n",
              " 'heart',\n",
              " 'beating',\n",
              " 'pulses',\n",
              " 'start',\n",
              " 'Cathedrals',\n",
              " 'heart',\n",
              " 'saw',\n",
              " 'oh',\n",
              " 'light',\n",
              " 'swear',\n",
              " 'emerge',\n",
              " 'blinking',\n",
              " 'tell',\n",
              " \"'s\",\n",
              " 'alright',\n",
              " 'soar',\n",
              " 'walls',\n",
              " 'every',\n",
              " 'siren',\n",
              " 'symphony',\n",
              " 'every',\n",
              " 'tear',\n",
              " \"'s\",\n",
              " 'waterfall',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'hurt',\n",
              " 'hurt',\n",
              " 'bad',\n",
              " 'still',\n",
              " \"'ll\",\n",
              " 'raise',\n",
              " 'flag',\n",
              " 'Oh',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall']"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Perform lemmatization using WordNetLemmatizer on our tokens\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens_lemmatized = [lemmatizer.lemmatize(token) for token in tokens_no_stop_words]\n",
        "tokens_lemmatized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH_UZPVzY-A0",
        "outputId": "cb45b77d-9e8c-462f-c569-448ae2fdd77a"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'record',\n",
              " 'shut',\n",
              " 'world',\n",
              " 'outside',\n",
              " 'light',\n",
              " 'come',\n",
              " 'Maybe',\n",
              " 'street',\n",
              " 'alight',\n",
              " 'maybe',\n",
              " 'tree',\n",
              " 'gone',\n",
              " 'feel',\n",
              " 'heart',\n",
              " 'start',\n",
              " 'beating',\n",
              " 'favourite',\n",
              " 'song',\n",
              " 'kid',\n",
              " 'dance',\n",
              " 'kid',\n",
              " 'night',\n",
              " 'Monday',\n",
              " 'morning',\n",
              " 'feel',\n",
              " 'another',\n",
              " 'life',\n",
              " 'turn',\n",
              " 'music',\n",
              " \"'m\",\n",
              " 'roll',\n",
              " 'time',\n",
              " 'heaven',\n",
              " 'sight',\n",
              " 'turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'record',\n",
              " 'underneath',\n",
              " 'rubble',\n",
              " 'sing',\n",
              " 'rebel',\n",
              " 'song',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'see',\n",
              " 'another',\n",
              " 'generation',\n",
              " 'drop',\n",
              " \"'d\",\n",
              " 'rather',\n",
              " 'comma',\n",
              " 'full',\n",
              " 'stop',\n",
              " 'Maybe',\n",
              " \"'m\",\n",
              " 'black',\n",
              " 'maybe',\n",
              " \"'m\",\n",
              " 'knee',\n",
              " 'Maybe',\n",
              " \"'m\",\n",
              " 'gap',\n",
              " 'two',\n",
              " 'trapeze',\n",
              " 'heart',\n",
              " 'beating',\n",
              " 'pulse',\n",
              " 'start',\n",
              " 'Cathedrals',\n",
              " 'heart',\n",
              " 'saw',\n",
              " 'oh',\n",
              " 'light',\n",
              " 'swear',\n",
              " 'emerge',\n",
              " 'blinking',\n",
              " 'tell',\n",
              " \"'s\",\n",
              " 'alright',\n",
              " 'soar',\n",
              " 'wall',\n",
              " 'every',\n",
              " 'siren',\n",
              " 'symphony',\n",
              " 'every',\n",
              " 'tear',\n",
              " \"'s\",\n",
              " 'waterfall',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'waterfall',\n",
              " 'Oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'hurt',\n",
              " 'hurt',\n",
              " 'bad',\n",
              " 'still',\n",
              " \"'ll\",\n",
              " 'raise',\n",
              " 'flag',\n",
              " 'Oh',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'tear',\n",
              " 'Every',\n",
              " 'teardrop',\n",
              " 'waterfall']"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. use the function pos_tag of NLTK to perform POS-tagging and print the result\n",
        "pos_tagged = nltk.pos_tag(tokens_lemmatized)\n",
        "pos_tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isDoUJggZB0d",
        "outputId": "3cb86179-1eeb-4a90-a39c-3e3565318063"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " ('got', 'VBD'),\n",
              " ('record', 'NN'),\n",
              " ('shut', 'NN'),\n",
              " ('world', 'NN'),\n",
              " ('outside', 'IN'),\n",
              " ('light', 'JJ'),\n",
              " ('come', 'VBP'),\n",
              " ('Maybe', 'NNP'),\n",
              " ('street', 'NN'),\n",
              " ('alight', 'VBD'),\n",
              " ('maybe', 'RB'),\n",
              " ('tree', 'JJ'),\n",
              " ('gone', 'VBN'),\n",
              " ('feel', 'JJ'),\n",
              " ('heart', 'NN'),\n",
              " ('start', 'NN'),\n",
              " ('beating', 'VBG'),\n",
              " ('favourite', 'NN'),\n",
              " ('song', 'NN'),\n",
              " ('kid', 'NN'),\n",
              " ('dance', 'NN'),\n",
              " ('kid', 'NN'),\n",
              " ('night', 'NN'),\n",
              " ('Monday', 'NNP'),\n",
              " ('morning', 'NN'),\n",
              " ('feel', 'NN'),\n",
              " ('another', 'DT'),\n",
              " ('life', 'NN'),\n",
              " ('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('roll', 'JJ'),\n",
              " ('time', 'NN'),\n",
              " ('heaven', 'VBN'),\n",
              " ('sight', 'JJ'),\n",
              " ('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " ('got', 'VBD'),\n",
              " ('record', 'JJ'),\n",
              " ('underneath', 'NN'),\n",
              " ('rubble', 'JJ'),\n",
              " ('sing', 'VBG'),\n",
              " ('rebel', 'NN'),\n",
              " ('song', 'VBP'),\n",
              " (\"n't\", 'RB'),\n",
              " ('want', 'VB'),\n",
              " ('see', 'VB'),\n",
              " ('another', 'DT'),\n",
              " ('generation', 'NN'),\n",
              " ('drop', 'NN'),\n",
              " (\"'d\", 'MD'),\n",
              " ('rather', 'RB'),\n",
              " ('comma', 'VB'),\n",
              " ('full', 'JJ'),\n",
              " ('stop', 'NN'),\n",
              " ('Maybe', 'NNP'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('black', 'JJ'),\n",
              " ('maybe', 'RB'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('knee', 'JJ'),\n",
              " ('Maybe', 'NNP'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('gap', 'JJ'),\n",
              " ('two', 'CD'),\n",
              " ('trapeze', 'JJ'),\n",
              " ('heart', 'NN'),\n",
              " ('beating', 'VBG'),\n",
              " ('pulse', 'JJ'),\n",
              " ('start', 'NN'),\n",
              " ('Cathedrals', 'NNP'),\n",
              " ('heart', 'NN'),\n",
              " ('saw', 'VBD'),\n",
              " ('oh', 'JJ'),\n",
              " ('light', 'JJ'),\n",
              " ('swear', 'JJ'),\n",
              " ('emerge', 'NN'),\n",
              " ('blinking', 'VBG'),\n",
              " ('tell', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('alright', 'NN'),\n",
              " ('soar', 'VB'),\n",
              " ('wall', 'NN'),\n",
              " ('every', 'DT'),\n",
              " ('siren', 'NN'),\n",
              " ('symphony', 'NN'),\n",
              " ('every', 'DT'),\n",
              " ('tear', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('waterfall', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('oh', 'VBZ'),\n",
              " ('oh', 'UH'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('oh', 'VBZ'),\n",
              " ('oh', 'JJ'),\n",
              " ('hurt', 'NN'),\n",
              " ('hurt', 'VBD'),\n",
              " ('bad', 'JJ'),\n",
              " ('still', 'RB'),\n",
              " (\"'ll\", 'MD'),\n",
              " ('raise', 'VB'),\n",
              " ('flag', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'VBD'),\n",
              " ('wa-aterfall', 'JJ'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'VBD'),\n",
              " ('wa-aterfall', 'JJ'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnPiEhTEZCqN",
        "outputId": "c12d98d8-a1cb-4d41-f6d0-7669f0c0b57f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Perform the lemmatization properly\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "pos_tagged_lemmatized = []\n",
        "for word, tag in pos_tagged:\n",
        "    pos = get_wordnet_pos(tag)\n",
        "    lemmatized_word = lemmatizer.lemmatize(word, pos=pos)\n",
        "    pos_tagged_lemmatized.append((lemmatized_word, tag))\n",
        "pos_tagged_lemmatized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjiEixyDZG3F",
        "outputId": "98ab1a44-7e24-4dc8-f9fa-892d8bfe2aea"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " ('get', 'VBD'),\n",
              " ('record', 'NN'),\n",
              " ('shut', 'NN'),\n",
              " ('world', 'NN'),\n",
              " ('outside', 'IN'),\n",
              " ('light', 'JJ'),\n",
              " ('come', 'VBP'),\n",
              " ('Maybe', 'NNP'),\n",
              " ('street', 'NN'),\n",
              " ('alight', 'VBD'),\n",
              " ('maybe', 'RB'),\n",
              " ('tree', 'JJ'),\n",
              " ('go', 'VBN'),\n",
              " ('feel', 'JJ'),\n",
              " ('heart', 'NN'),\n",
              " ('start', 'NN'),\n",
              " ('beat', 'VBG'),\n",
              " ('favourite', 'NN'),\n",
              " ('song', 'NN'),\n",
              " ('kid', 'NN'),\n",
              " ('dance', 'NN'),\n",
              " ('kid', 'NN'),\n",
              " ('night', 'NN'),\n",
              " ('Monday', 'NNP'),\n",
              " ('morning', 'NN'),\n",
              " ('feel', 'NN'),\n",
              " ('another', 'DT'),\n",
              " ('life', 'NN'),\n",
              " ('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('roll', 'JJ'),\n",
              " ('time', 'NN'),\n",
              " ('heaven', 'VBN'),\n",
              " ('sight', 'JJ'),\n",
              " ('turn', 'NN'),\n",
              " ('music', 'NN'),\n",
              " ('get', 'VBD'),\n",
              " ('record', 'JJ'),\n",
              " ('underneath', 'NN'),\n",
              " ('rubble', 'JJ'),\n",
              " ('sing', 'VBG'),\n",
              " ('rebel', 'NN'),\n",
              " ('song', 'VBP'),\n",
              " (\"n't\", 'RB'),\n",
              " ('want', 'VB'),\n",
              " ('see', 'VB'),\n",
              " ('another', 'DT'),\n",
              " ('generation', 'NN'),\n",
              " ('drop', 'NN'),\n",
              " (\"'d\", 'MD'),\n",
              " ('rather', 'RB'),\n",
              " ('comma', 'VB'),\n",
              " ('full', 'JJ'),\n",
              " ('stop', 'NN'),\n",
              " ('Maybe', 'NNP'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('black', 'JJ'),\n",
              " ('maybe', 'RB'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('knee', 'JJ'),\n",
              " ('Maybe', 'NNP'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('gap', 'JJ'),\n",
              " ('two', 'CD'),\n",
              " ('trapeze', 'JJ'),\n",
              " ('heart', 'NN'),\n",
              " ('beat', 'VBG'),\n",
              " ('pulse', 'JJ'),\n",
              " ('start', 'NN'),\n",
              " ('Cathedrals', 'NNP'),\n",
              " ('heart', 'NN'),\n",
              " ('saw', 'VBD'),\n",
              " ('oh', 'JJ'),\n",
              " ('light', 'JJ'),\n",
              " ('swear', 'JJ'),\n",
              " ('emerge', 'NN'),\n",
              " ('blink', 'VBG'),\n",
              " ('tell', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('alright', 'NN'),\n",
              " ('soar', 'VB'),\n",
              " ('wall', 'NN'),\n",
              " ('every', 'DT'),\n",
              " ('siren', 'NN'),\n",
              " ('symphony', 'NN'),\n",
              " ('every', 'DT'),\n",
              " ('tear', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('waterfall', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('oh', 'VBZ'),\n",
              " ('oh', 'UH'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('oh', 'VBZ'),\n",
              " ('oh', 'JJ'),\n",
              " ('hurt', 'NN'),\n",
              " ('hurt', 'VBD'),\n",
              " ('bad', 'JJ'),\n",
              " ('still', 'RB'),\n",
              " (\"'ll\", 'MD'),\n",
              " ('raise', 'VB'),\n",
              " ('flag', 'NN'),\n",
              " ('Oh', 'NNP'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'VBD'),\n",
              " ('wa-aterfall', 'JJ'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'NN'),\n",
              " ('wa', 'VBD'),\n",
              " ('wa-aterfall', 'JJ'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('tear', 'NN'),\n",
              " ('Every', 'NNP'),\n",
              " ('teardrop', 'NN'),\n",
              " ('waterfall', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Perform stemming\n",
        "stemmer = PorterStemmer()\n",
        "tokens_stemmed = [stemmer.stem(token) for token in tokens_no_stop_words]\n",
        "tokens_stemmed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV8wxAgZZQ9W",
        "outputId": "9c711f05-0dc6-447b-cca6-94400fa08713"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'record',\n",
              " 'shut',\n",
              " 'world',\n",
              " 'outsid',\n",
              " 'light',\n",
              " 'come',\n",
              " 'mayb',\n",
              " 'street',\n",
              " 'alight',\n",
              " 'mayb',\n",
              " 'tree',\n",
              " 'gone',\n",
              " 'feel',\n",
              " 'heart',\n",
              " 'start',\n",
              " 'beat',\n",
              " 'favourit',\n",
              " 'song',\n",
              " 'kid',\n",
              " 'danc',\n",
              " 'kid',\n",
              " 'night',\n",
              " 'monday',\n",
              " 'morn',\n",
              " 'feel',\n",
              " 'anoth',\n",
              " 'life',\n",
              " 'turn',\n",
              " 'music',\n",
              " \"'m\",\n",
              " 'roll',\n",
              " 'time',\n",
              " 'heaven',\n",
              " 'sight',\n",
              " 'turn',\n",
              " 'music',\n",
              " 'got',\n",
              " 'record',\n",
              " 'underneath',\n",
              " 'rubbl',\n",
              " 'sing',\n",
              " 'rebel',\n",
              " 'song',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'see',\n",
              " 'anoth',\n",
              " 'gener',\n",
              " 'drop',\n",
              " \"'d\",\n",
              " 'rather',\n",
              " 'comma',\n",
              " 'full',\n",
              " 'stop',\n",
              " 'mayb',\n",
              " \"'m\",\n",
              " 'black',\n",
              " 'mayb',\n",
              " \"'m\",\n",
              " 'knee',\n",
              " 'mayb',\n",
              " \"'m\",\n",
              " 'gap',\n",
              " 'two',\n",
              " 'trapez',\n",
              " 'heart',\n",
              " 'beat',\n",
              " 'puls',\n",
              " 'start',\n",
              " 'cathedr',\n",
              " 'heart',\n",
              " 'saw',\n",
              " 'oh',\n",
              " 'light',\n",
              " 'swear',\n",
              " 'emerg',\n",
              " 'blink',\n",
              " 'tell',\n",
              " \"'s\",\n",
              " 'alright',\n",
              " 'soar',\n",
              " 'wall',\n",
              " 'everi',\n",
              " 'siren',\n",
              " 'symphoni',\n",
              " 'everi',\n",
              " 'tear',\n",
              " \"'s\",\n",
              " 'waterfal',\n",
              " 'waterfal',\n",
              " 'oh',\n",
              " 'waterfal',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'waterfal',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'waterfal',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'oh',\n",
              " 'hurt',\n",
              " 'hurt',\n",
              " 'bad',\n",
              " 'still',\n",
              " \"'ll\",\n",
              " 'rais',\n",
              " 'flag',\n",
              " 'oh',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfal',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa',\n",
              " 'wa-aterfal',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'teardrop',\n",
              " 'waterfal',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'teardrop',\n",
              " 'waterfal',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'tear',\n",
              " 'everi',\n",
              " 'teardrop',\n",
              " 'waterfal']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Bag-of-words"
      ],
      "metadata": {
        "id": "dV89n-SogTh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NLTK and all the needed libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "fAdcsufTgUu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fcdc3a-be91-4be0-b792-1eb47bc6bb24"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/coldplay.csv')\n",
        "print(len(data))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "o0TJuWSQaXGG",
        "outputId": "10a92ef2-9414-45a9-b158-52023a801a2f"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Artist                           Song  \\\n",
              "0  Coldplay                 Another's Arms   \n",
              "1  Coldplay                Bigger Stronger   \n",
              "2  Coldplay                       Daylight   \n",
              "3  Coldplay                       Everglow   \n",
              "4  Coldplay  Every Teardrop Is A Waterfall   \n",
              "\n",
              "                                                Link  \\\n",
              "0            /c/coldplay/anothers+arms_21079526.html   \n",
              "1          /c/coldplay/bigger+stronger_20032648.html   \n",
              "2                 /c/coldplay/daylight_20032625.html   \n",
              "3                 /c/coldplay/everglow_21104546.html   \n",
              "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
              "\n",
              "                                              Lyrics  \n",
              "0  Late night watching tv  \\nUsed to be you here ...  \n",
              "1  I want to be bigger stronger drive a faster ca...  \n",
              "2  To my surprise, and my delight  \\nI saw sunris...  \n",
              "3  Oh, they say people come  \\nThey say people go...  \n",
              "4  I turn the music up, I got my records on  \\nI ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa71fe92-9cf2-4e0f-ac14-153a00c7c3fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>Link</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Another's Arms</td>\n",
              "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
              "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Bigger Stronger</td>\n",
              "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
              "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Daylight</td>\n",
              "      <td>/c/coldplay/daylight_20032625.html</td>\n",
              "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Everglow</td>\n",
              "      <td>/c/coldplay/everglow_21104546.html</td>\n",
              "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Every Teardrop Is A Waterfall</td>\n",
              "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
              "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa71fe92-9cf2-4e0f-ac14-153a00c7c3fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa71fe92-9cf2-4e0f-ac14-153a00c7c3fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa71fe92-9cf2-4e0f-ac14-153a00c7c3fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOt_EZbyacsN",
        "outputId": "f92b2eb6-47e1-4c95-c7d3-c673bfbeba94"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Artist  120 non-null    object\n",
            " 1   Song    120 non-null    object\n",
            " 2   Link    120 non-null    object\n",
            " 3   Lyrics  120 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 3.9+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Compute a BOW to format: (120, 1569)\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(data['Lyrics'].values)\n",
        "bow_df = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(bow_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfNxc5vXbL--",
        "outputId": "7907e3be-cf90-40fe-89af-366fc6de7f9e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 1776)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a new dataframe containing the BOW outputs and the corresponding words as columns. And print it\n",
        "bow_words_df = pd.concat([data[['Artist', 'Song']], bow_df], axis=1)\n",
        "print(bow_words_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kk-qQMJbPjv",
        "outputId": "b63ef0a3-fa89-40b6-e2b4-289d7c758824"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Artist                           Song  10  2000  2gether  76543  \\\n",
            "0    Coldplay                 Another's Arms   0     0        0      0   \n",
            "1    Coldplay                Bigger Stronger   0     0        0      0   \n",
            "2    Coldplay                       Daylight   0     0        0      0   \n",
            "3    Coldplay                       Everglow   0     0        0      0   \n",
            "4    Coldplay  Every Teardrop Is A Waterfall   0     0        0      0   \n",
            "..        ...                            ...  ..   ...      ...    ...   \n",
            "115  Coldplay           Hymn For The Weekend   0     0        0      0   \n",
            "116  Coldplay                    In My Place   0     0        0      0   \n",
            "117  Coldplay                            Ink   0     0        1      0   \n",
            "118  Coldplay              Ladder To The Sun   0     0        0      0   \n",
            "119  Coldplay                           Lost   0     0        0      0   \n",
            "\n",
            "     aaaaaah  aaaaah  aaaah  about  ...  yellow  yes  yesterday  yet  you  \\\n",
            "0          0       0      0      0  ...       0    0          0    0    4   \n",
            "1          0       0      0      0  ...       0    0          0    0    0   \n",
            "2          0       0      0      0  ...       0    0          0    0    0   \n",
            "3          0       0      0      0  ...       0    0          0    0   16   \n",
            "4          0       0      0      0  ...       0    0          0    0    2   \n",
            "..       ...     ...    ...    ...  ...     ...  ...        ...  ...  ...   \n",
            "115        0       0      0      1  ...       0    0          0    0    5   \n",
            "116        0       0      0      0  ...       0    0          0    0    9   \n",
            "117        0       0      0      0  ...       0    0          0    0    7   \n",
            "118        0       0      0      0  ...       0    0          0    0   16   \n",
            "119        0       0      0      0  ...       0    0          0    0    5   \n",
            "\n",
            "     young  your  yours  yourself  yuletide  \n",
            "0        0     4      0         2         0  \n",
            "1        0     0      0         0         0  \n",
            "2        0     0      0         0         0  \n",
            "3        0     0      0         0         0  \n",
            "4        0     0      0         0         0  \n",
            "..     ...   ...    ...       ...       ...  \n",
            "115      0     3      0         0         0  \n",
            "116      0     0      0         0         0  \n",
            "117      0     4      0         0         0  \n",
            "118      0     1      0         0         0  \n",
            "119      0     0      0         0         0  \n",
            "\n",
            "[120 rows x 1778 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Find the most common word in the BOW\n",
        "sum_bow = bow_df.sum()\n",
        "most_common_word = sum_bow.idxmax()\n",
        "most_common_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "gTgtk1DTbU29",
        "outputId": "9e655a8c-318b-45ed-a968-aeddbf727331"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Print the 10 most used words by Coldplay\n",
        "coldplay_bow_df = bow_words_df[bow_words_df['Artist'] == 'Coldplay']\n",
        "coldplay_sum_bow = coldplay_bow_df.iloc[:, 2:].sum()\n",
        "top_10_words = coldplay_sum_bow.nlargest(10)\n",
        "print(top_10_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER89wuZvbaC-",
        "outputId": "024a9b18-27c0-497e-b9e9-0cdaaa9ff768"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you    994\n",
            "the    777\n",
            "and    650\n",
            "to     481\n",
            "it     458\n",
            "oh     334\n",
            "in     318\n",
            "me     314\n",
            "my     288\n",
            "on     285\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**III. Text Similarity**"
      ],
      "metadata": {
        "id": "au5AfuukgVEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Similarity metrics"
      ],
      "metadata": {
        "id": "D05ejRO_gbuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import needed libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "yhV8hYS_gcCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = \"Outside the classroom, Stallman pursued his studies with even more diligence, rushing off to fulfill his laboratory-assistant duties at Rockefeller University during the week and dodging the Vietnam protesters on his way to Saturday school at Columbia. It was there, while the rest of the Science Honors Program students sat around discussing their college choices, that Stallman finally took a moment to participate in the preclass bull session.\"\n",
        "B = \"To facilitate the process, AI Lab hackers had built a system that displayed both the source and display modes on a split screen. Despite this innovative hack, switching from mode to mode was still a nuisance.\"\n",
        "C = \"With no dorm and no dancing, Stallman's social universe imploded. Like an astronaut experiencing the aftereffects of zero-gravity, Stallman found that his ability to interact with nonhackers, especially female nonhackers, had atrophied significantly. After 16 weeks in the AI Lab, the self confidence he'd been quietly accumulating during his 4 years at Harvard was virtually gone.\""
      ],
      "metadata": {
        "id": "E9KPi33_pEEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the sentences\n",
        "A_list = A.split()\n",
        "B_list = B.split()\n",
        "C_list = C.split()\n",
        "\n",
        "# Compute the intersection and union\n",
        "A_set = set(A_list)\n",
        "B_set = set(B_list)\n",
        "C_set = set(C_list)\n",
        "AB_intersection = A_set.intersection(B_set)\n",
        "AB_union = A_set.union(B_set)\n",
        "AC_intersection = A_set.intersection(C_set)\n",
        "AC_union = A_set.union(C_set)\n",
        "BC_intersection = B_set.intersection(C_set)\n",
        "BC_union = B_set.union(C_set)\n",
        "\n",
        "# Compute and print the Jaccard Similarity\n",
        "AB_jaccard = len(AB_intersection) / len(AB_union)\n",
        "AC_jaccard = len(AC_intersection) / len(AC_union)\n",
        "BC_jaccard = len(BC_intersection) / len(BC_union)"
      ],
      "metadata": {
        "id": "C1PpIQ1Uq3LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Jaccard Similarity AB:\", AB_jaccard)\n",
        "print(\"Jaccard Similarity BC:\", BC_jaccard)\n",
        "print(\"Jaccard Similarity AC:\", AC_jaccard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co6nTzVKpJV0",
        "outputId": "2bf1707c-2fa9-48c8-a73c-9329e20cf1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity AB: 0.08536585365853659\n",
            "Jaccard Similarity BC: 0.09210526315789473\n",
            "Jaccard Similarity AC: 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [A, B, C]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "print(f\"cos(A, B): [[{cosine_sim_matrix[0][1]}]]\")\n",
        "print(f\"cos(B, C): [[{cosine_sim_matrix[1][2]}]]\")\n",
        "print(f\"cos(A, C): [[{cosine_sim_matrix[0][2]}]]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl0q7W7opMOd",
        "outputId": "ed2f8ef5-7453-4bcf-8a00-97ddbfd1ce9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cos(A, B): [[0.16793269576264072]]\n",
            "cos(B, C): [[0.13618963113796592]]\n",
            "cos(A, C): [[0.2850296032333907]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- Is it consistent with the Jaccard values? --\n",
        "\n",
        "No, the cosine similarity values are not consistent with the Jaccard values. The Jaccard similarity values indicate that sentences A and C as well as sentences B and C share some common words, while sentences A and B have no common words. However, the cosine similarity values indicate that sentences A and C as well as sentences C and A have the highest similarity, while all other pairs of sentences have no similarity. This discrepancy may be due to the fact that Jaccard similarity only compares the overlap in the set of words between two sentences, while cosine similarity takes into account the frequency of each word in the sentences as well."
      ],
      "metadata": {
        "id": "pT6s0jOqpOs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. TF-IDF "
      ],
      "metadata": {
        "id": "y0q2E4icgcUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "I_JDWZuOgdn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5adf6f5-e84c-4c81-a45c-f8820382bf88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/headlines.csv')\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "Xze3AeQVspCm",
        "outputId": "bfaea2d7-b11a-4cc1-c7b0-3dcd4b910368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20170721  algorithms can make decisions on behalf of fed...\n",
              "1      20170721  andrew forrests fmg to appeal pilbara native t...\n",
              "2      20170721                           a rural mural in thallan\n",
              "3      20170721  australia church risks becoming haven for abusers\n",
              "4      20170721  australian company usgfx embroiled in shanghai..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48448498-3e60-4baa-9925-768332f59af8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20170721</td>\n",
              "      <td>algorithms can make decisions on behalf of fed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20170721</td>\n",
              "      <td>andrew forrests fmg to appeal pilbara native t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20170721</td>\n",
              "      <td>a rural mural in thallan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20170721</td>\n",
              "      <td>australia church risks becoming haven for abusers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20170721</td>\n",
              "      <td>australian company usgfx embroiled in shanghai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48448498-3e60-4baa-9925-768332f59af8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48448498-3e60-4baa-9925-768332f59af8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48448498-3e60-4baa-9925-768332f59af8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zb1-eExs5vW",
        "outputId": "e899b199-b212-4cfa-fbe7-81120682e25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1999 entries, 0 to 1998\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   publish_date   1999 non-null   int64 \n",
            " 1   headline_text  1999 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 31.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for preprocessing\n",
        "def preprocess(text):\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "    # Remove stop words\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Stem\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "# Apply the preprocessing function to the 'headline_text' column\n",
        "df['headline_text'] = df['headline_text'].apply(preprocess)\n",
        "\n",
        "# Print the output\n",
        "print(df['headline_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88dtDKpfs71V",
        "outputId": "cc04e3b9-f18a-46d5-933c-4a1b0bdbdfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                algorithm make decis behalf feder minist\n",
            "1       andrew forrest fmg appeal pilbara nativ titl rule\n",
            "2                                     rural mural thallan\n",
            "3                        australia church risk becom abus\n",
            "4       australian compani usgfx embroil shanghai staf...\n",
            "                              ...                        \n",
            "1994    constitut avenu win top prize act architectu a...\n",
            "1995                              dark mofo number crunch\n",
            "1996    david petraeu say australia must firm south ch...\n",
            "1997    driverless car australia face challeng roo pro...\n",
            "1998                     drug compani criticis price hike\n",
            "Name: headline_text, Length: 1999, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer()\n",
        "bow_matrix = bow.fit_transform(df['headline_text'])\n",
        "\n",
        "# Print the shape ofthe BOW representation\n",
        "print(bow_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYnsG7I4s_Af",
        "outputId": "475f0659-4961-490a-e4e5-41162ff83672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1999, 4256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the TF using the BOW\n",
        "tf = bow_matrix.toarray()\n",
        "tf = np.divide(tf, np.sum(tf, axis=1, keepdims=True))\n",
        "print(tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mw5AuHHvb3H",
        "outputId": "e2bdf03e-3e10-4bb8-c6f6-0f5e98817a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the IDF\n",
        "idf = np.log(np.divide(len(df['headline_text']), np.count_nonzero(bow_matrix.toarray(), axis=0)))\n",
        "idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scVgGMEcvpaA",
        "outputId": "43e3e237-a41c-47a5-f4c7-4461ea9991d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.60040233, 7.60040233, 7.60040233, ..., 7.60040233, 7.60040233,\n",
              "       7.60040233])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the TF-IDF\n",
        "tf_idf = np.multiply(tf, idf)\n",
        "tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifQ2g2bqvt5X",
        "outputId": "e8541886-c5a3-4483-e6f9-11b852635b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the 10 words with the highest and lowest TF-IDF on average\n",
        "vocab = bow.get_feature_names_out()\n",
        "tf_idf_avg = np.mean(tf_idf, axis=0)\n",
        "sorted_indices = tf_idf_avg.argsort()\n",
        "\n",
        "print('10 words with the highest TF-IDF on average:')\n",
        "for i in range(1, 11):\n",
        "    word = vocab[sorted_indices[-i]]\n",
        "    print(f'{word}: {tf_idf_avg[sorted_indices[-i]]:.4f}')\n",
        "    \n",
        "print('10 words with the lowest TF-IDF on average:')\n",
        "for i in range(1, 11):\n",
        "    word = vocab[sorted_indices[i-1]]\n",
        "    print(f'{word}: {tf_idf_avg[sorted_indices[i-1]]:.4f}')"
      ],
      "metadata": {
        "id": "I2sUtToQzQiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db92922f-67af-4ca7-a818-9a3a5d18230c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words with the highest TF-IDF on average:\n",
            "australian: 0.0197\n",
            "australia: 0.0197\n",
            "new: 0.0170\n",
            "polic: 0.0145\n",
            "say: 0.0143\n",
            "market: 0.0138\n",
            "trump: 0.0133\n",
            "wa: 0.0127\n",
            "man: 0.0125\n",
            "sydney: 0.0119\n",
            "10 words with the lowest TF-IDF on average:\n",
            "haw: 0.0003\n",
            "geel: 0.0003\n",
            "adel: 0.0003\n",
            "coll: 0.0003\n",
            "nmfc: 0.0003\n",
            "gw: 0.0003\n",
            "melb: 0.0003\n",
            "gcfc: 0.0003\n",
            "syd: 0.0003\n",
            "nemtsov: 0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the TF-IDF using scikit learn\n",
        "tf_idf_sk = TfidfVectorizer()\n",
        "tf_idf_matrix = tf_idf_sk.fit_transform(df['headline_text'])\n",
        "\n",
        "# Print the 10 words with the highest and lowest TF-IDF on average using scikit learn\n",
        "vocab_sk = tf_idf_sk.get_feature_names_out()\n",
        "tf_idf_avg_sk = np.mean(tf_idf_matrix.toarray(), axis=0)\n",
        "sorted_indices_sk = tf_idf_avg_sk.argsort()\n",
        "\n",
        "print('10 words with the highest TF-IDF on average using scikit learn:')\n",
        "for i in range(1, 11):\n",
        "    word = vocab_sk[sorted_indices_sk[-i]]\n",
        "    print(f'{word}: {tf_idf_avg_sk[sorted_indices_sk[-i]]:.4f}')\n",
        "    \n",
        "print('10 words with the lowest TF-IDF on average using scikit learn:')\n",
        "for i in range(1, 11):\n",
        "    word = vocab_sk[sorted_indices_sk[i-1]]\n",
        "    print(f'{word}: {tf_idf_avg_sk[sorted_indices_sk[i-1]]:.4f}')"
      ],
      "metadata": {
        "id": "uhtPXgYg2a6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5edeaa02-1410-41ea-bb06-fab63decfb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words with the highest TF-IDF on average using scikit learn:\n",
            "australia: 0.0100\n",
            "australian: 0.0097\n",
            "new: 0.0087\n",
            "polic: 0.0077\n",
            "say: 0.0076\n",
            "trump: 0.0068\n",
            "man: 0.0065\n",
            "wa: 0.0063\n",
            "charg: 0.0060\n",
            "sydney: 0.0057\n",
            "10 words with the lowest TF-IDF on average using scikit learn:\n",
            "adel: 0.0002\n",
            "melb: 0.0002\n",
            "haw: 0.0002\n",
            "coll: 0.0002\n",
            "gw: 0.0002\n",
            "syd: 0.0002\n",
            "gcfc: 0.0002\n",
            "nmfc: 0.0002\n",
            "geel: 0.0002\n",
            "fabio: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Plagiarism checker "
      ],
      "metadata": {
        "id": "A2Tzgv6KgeAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "with open('A1.txt', 'r') as file:\n",
        "    A1 = file.readlines()[0]\n",
        "with open('Asource.txt', 'r') as file:\n",
        "    A0 = file.readlines()[0]\n",
        "with open('B1.txt', 'r') as file:\n",
        "    B1 = file.readlines()[0]\n",
        "with open('Bsource.txt', 'r') as file:\n",
        "    B0 = file.readlines()[0]\n",
        "with open('C1.txt', 'r') as file:\n",
        "    C1 = file.readlines()[0]\n",
        "with open('Csource.txt', 'r') as file:\n",
        "    C0 = file.readlines()[0]\n",
        "with open('D1.txt', 'r') as file:\n",
        "    D1 = file.readlines()[0]\n",
        "with open('D2.txt', 'r') as file:\n",
        "    D2 = file.readlines()[0]\n",
        "with open('Dsource.txt', 'r') as file:\n",
        "    D0 = file.readlines()[0]"
      ],
      "metadata": {
        "id": "az0jFIWkgfUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "bJoxXLuR37cx",
        "outputId": "c204341f-54b7-4b66-f6d6-29524f69ed26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Descartes has been heralded as the first modern philosopher. He is famous for having made an important connection between geometry and algebra, which allowed for the solving of geometrical problems by way of algebraic equations. He is also famous for having promoted a new conception of matter, which allowed for the accounting of physical phenomena by way of mechanical explanations. However, he is most famous for having written a relatively short work, Meditationes de Prima Philosophia (Meditations On First Philosophy), published in 1641, in which he provides a philosophical groundwork for the possibility of the sciences. (Smith, 2007).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of all documents\n",
        "alldata = [A0, A1, B0, B1, C0, C1, D0, D1, D2]"
      ],
      "metadata": {
        "id": "YM7R0XCL39Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute tf-idf for all documents\n",
        "tfvect = TfidfVectorizer()\n",
        "tfvect.fit(alldata)\n",
        "tfidf = tfvect.transform(alldata)\n",
        "\n",
        "TFIDFA = tfvect.transform([A0, A1]).toarray()\n",
        "TFIDFB = tfvect.transform([B0, B1]).toarray()\n",
        "TFIDFC = tfvect.transform([C0, C1]).toarray()\n",
        "TFIDFD = tfvect.transform([D0, D1, D2]).toarray()"
      ],
      "metadata": {
        "id": "FEXq5POn4vci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute pair-wise similarity\n",
        "similarityAA = cosine_similarity(TFIDFA)\n",
        "similarityBB = cosine_similarity(TFIDFB)\n",
        "similarityCC = cosine_similarity(TFIDFC)\n",
        "similarityDD = cosine_similarity(TFIDFD)\n",
        "\n",
        "similarityAll = cosine_similarity(tfidf)"
      ],
      "metadata": {
        "id": "jSYvSgOC5Cqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarityAA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nn-_62-5ERT",
        "outputId": "2497ced8-3316-4846-e60d-e811eb1df861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.81898863],\n",
              "       [0.81898863, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarityBB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePdV4htV5JvS",
        "outputId": "f6464f3c-a10a-43d3-c5be-6341b2d20ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.63747903],\n",
              "       [0.63747903, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarityCC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQaOncq6AK7",
        "outputId": "a01e99b4-172a-4a8e-83dc-835893a59565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.85723864],\n",
              "       [0.85723864, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarityDD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkLXmrCh6CGj",
        "outputId": "b6add1fb-beb2-45dd-b6ac-e8f5c17c0d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.92754461, 0.45775827],\n",
              "       [0.92754461, 1.        , 0.47179638],\n",
              "       [0.45775827, 0.47179638, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarityAll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48lQLWUy6E8L",
        "outputId": "51cdef3a-c1dc-4a60-8713-29b1d855fef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.81898863, 0.10748497, 0.12736224, 0.24491604,\n",
              "        0.29501242, 0.2530779 , 0.2146434 , 0.18585492],\n",
              "       [0.81898863, 1.        , 0.10940658, 0.12644471, 0.21239125,\n",
              "        0.25583485, 0.214717  , 0.17937458, 0.16807197],\n",
              "       [0.10748497, 0.10940658, 1.        , 0.63747903, 0.08804551,\n",
              "        0.09372089, 0.08509508, 0.07946359, 0.10627147],\n",
              "       [0.12736224, 0.12644471, 0.63747903, 1.        , 0.08730757,\n",
              "        0.08893992, 0.12527568, 0.1207279 , 0.12910021],\n",
              "       [0.24491604, 0.21239125, 0.08804551, 0.08730757, 1.        ,\n",
              "        0.85723864, 0.20151171, 0.16200275, 0.14447728],\n",
              "       [0.29501242, 0.25583485, 0.09372089, 0.08893992, 0.85723864,\n",
              "        1.        , 0.22326634, 0.1806631 , 0.1558733 ],\n",
              "       [0.2530779 , 0.214717  , 0.08509508, 0.12527568, 0.20151171,\n",
              "        0.22326634, 1.        , 0.92754461, 0.45775827],\n",
              "       [0.2146434 , 0.17937458, 0.07946359, 0.1207279 , 0.16200275,\n",
              "        0.1806631 , 0.92754461, 1.        , 0.47179638],\n",
              "       [0.18585492, 0.16807197, 0.10627147, 0.12910021, 0.14447728,\n",
              "        0.1558733 , 0.45775827, 0.47179638, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show pair-wise similarity\n",
        "plt.imshow(similarityAll)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dT9mxZ4g7LWs",
        "outputId": "3c4744d3-2ed7-4fb1-f8ca-5933bbd7645a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the pairwise cosine similarity between all documents\n",
        "similarityAll = cosine_similarity(tfidf)\n",
        "\n",
        "pred_plagiarism = similarityAll > 0.2\n",
        "\n",
        "# Plot the pairwise similarity matrix as a heatmap\n",
        "plt.imshow(similarityAll)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "mK_bZAQR7owC",
        "outputId": "c10c1521-7486-4b7e-af2c-08fa0cf912a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the true labels matrix\n",
        "documents = ['A0', 'A1', 'B0', 'B1', 'C0', 'C1', 'D0', 'D1', 'D2']\n",
        "doc_index = {doc: i for i, doc in enumerate(documents)}\n",
        "labels = [('A0', 'A1', 1), ('A0', 'B0', 0), ('A0', 'B1', 0), ('A0', 'C0', 0), ('A0', 'C1', 0), ('A0', 'D0', 0), ('A0', 'D1', 0), ('A0', 'D2', 0), ('A1', 'B0', 0), ('A1', 'B1', 0), ('A1', 'C0', 0), ('A1', 'C1', 0), ('A1', 'D0', 0), ('A1', 'D1', 0), ('A1', 'D2', 0), ('B0', 'B1', 1), ('B0', 'C0', 0), ('B0', 'C1', 0), ('B0', 'D0', 0), ('B0', 'D1', 0), ('B0', 'D2', 0), ('B1', 'C0', 0), ('B1', 'C1', 0), ('B1', 'D0', 0), ('B1', 'D1', 0), ('B1', 'D2', 0), ('C0', 'C1', 1), ('C0', 'D0', 0), ('C0', 'D1', 0), ('C0', 'D2', 0), ('C1', 'D0', 0), ('C1', 'D1', 0), ('C1', 'D2', 0), ('D0', 'D1', 0), ('D0', 'D2', 1), ('D1', 'D2', 1)]\n",
        "\n",
        "real_plagiarism = np.zeros((9,9))\n",
        "for label in labels:\n",
        "    i = doc_index[label[0]]\n",
        "    j = doc_index[label[1]]\n",
        "    real_plagiarism[i][j] = label[2]\n",
        "    real_plagiarism[j][i] = label[2]\n",
        "\n",
        "plt.imshow(real_plagiarism)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bx115OZr9g1j",
        "outputId": "bee88330-291d-4df5-e253-e986f5668c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the accuracy score based on true matrices\n",
        "pred_plagiarism = similarityAll > 0.2\n",
        "acc_score = accuracy_score(real_plagiarism.flatten(), pred_plagiarism.flatten())\n",
        "\n",
        "print('Accuracy score:', acc_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdiTC8WS_QS-",
        "outputId": "d2738209-916f-4cd0-cde1-50c611bbf49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.6419753086419753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV. Text Classification**"
      ],
      "metadata": {
        "id": "Y61GUlpCgfvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NLTK and all the needed libraries\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score"
      ],
      "metadata": {
        "id": "NBWa9sqXgls9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816a8f1b-29f6-46ac-972f-72ce95079c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load the dataset \n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tOjckvlRoBXD",
        "outputId": "d7658906-69b3-48f6-b6f6-8dd396a53515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Class                                            Message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15361436-0294-40c5-a58b-bdcf005f4860\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15361436-0294-40c5-a58b-bdcf005f4860')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15361436-0294-40c5-a58b-bdcf005f4860 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15361436-0294-40c5-a58b-bdcf005f4860');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: explore the dataset\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPI-4DsmoGeL",
        "outputId": "63a16365-f6a3-4f6f-f884-8912281cdff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Class    5572 non-null   object\n",
            " 1   Message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Perform preprocessing over all the text\n",
        "\n",
        "# Rename the columns of the dataset to `Class` and `Message`\n",
        "df.columns = ['Class', 'Message']\n",
        "\n",
        "# Convert the text to lowercase\n",
        "df['Message'] = df['Message'].str.lower()\n",
        "\n",
        "# Remove non-alphanumeric characters\n",
        "df['Message'] = df['Message'].str.replace('[^a-zA-Z0-9 ]', '', regex=True)\n",
        "\n",
        "# Remove stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['Message'].apply(lambda x: [word for word in x.split() if word not in stop_words])\n",
        "\n",
        "# Stem words\n",
        "stemmer = PorterStemmer()\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "\n",
        "# Lemmatize words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Print the tokens column\n",
        "print(df['tokens'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7nd7mklob3t",
        "outputId": "729a522b-60e8-4e98-94d2-28d55c4bb07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       [go, jurong, point, crazi, avail, bugi, n, gre...\n",
            "1                            [ok, lar, joke, wif, u, oni]\n",
            "2       [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
            "3           [u, dun, say, earli, hor, u, c, alreadi, say]\n",
            "4       [nah, dont, think, goe, usf, live, around, tho...\n",
            "                              ...                        \n",
            "5567    [2nd, time, tri, 2, contact, u, u, 750, pound,...\n",
            "5568                          [b, go, esplanad, fr, home]\n",
            "5569                         [piti, mood, soani, suggest]\n",
            "5570    [guy, bitch, act, like, id, interest, buy, som...\n",
            "5571                                   [rofl, true, name]\n",
            "Name: tokens, Length: 5572, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Compute the Bag of Words (BOW)\n",
        "bow = vectorizer.fit_transform(df['Message'])\n",
        "print(bow.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dHBnVgosGln",
        "outputId": "eb8005b7-3178-47b3-eac4-b62f43f68fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 9539)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe with the BOW\n",
        "bow_df = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Print the new dataframe with the BOW\n",
        "print(bow_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tL3rAedsJVe",
        "outputId": "eef5bdad-ecd8-4616-bab0-d0e9203d57e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      008704050406  0089my  0121  01223585236  01223585334  0125698789  02  \\\n",
            "0                0       0     0            0            0           0   0   \n",
            "1                0       0     0            0            0           0   0   \n",
            "2                0       0     0            0            0           0   0   \n",
            "3                0       0     0            0            0           0   0   \n",
            "4                0       0     0            0            0           0   0   \n",
            "...            ...     ...   ...          ...          ...         ...  ..   \n",
            "5567             0       0     0            0            0           0   0   \n",
            "5568             0       0     0            0            0           0   0   \n",
            "5569             0       0     0            0            0           0   0   \n",
            "5570             0       0     0            0            0           0   0   \n",
            "5571             0       0     0            0            0           0   0   \n",
            "\n",
            "      020603  0207  02070836089  ...  zebra  zed  zeros  zhong  zindgi  zoe  \\\n",
            "0          0     0            0  ...      0    0      0      0       0    0   \n",
            "1          0     0            0  ...      0    0      0      0       0    0   \n",
            "2          0     0            0  ...      0    0      0      0       0    0   \n",
            "3          0     0            0  ...      0    0      0      0       0    0   \n",
            "4          0     0            0  ...      0    0      0      0       0    0   \n",
            "...      ...   ...          ...  ...    ...  ...    ...    ...     ...  ...   \n",
            "5567       0     0            0  ...      0    0      0      0       0    0   \n",
            "5568       0     0            0  ...      0    0      0      0       0    0   \n",
            "5569       0     0            0  ...      0    0      0      0       0    0   \n",
            "5570       0     0            0  ...      0    0      0      0       0    0   \n",
            "5571       0     0            0  ...      0    0      0      0       0    0   \n",
            "\n",
            "      zogtorius  zoom  zouk  zyada  \n",
            "0             0     0     0      0  \n",
            "1             0     0     0      0  \n",
            "2             0     0     0      0  \n",
            "3             0     0     0      0  \n",
            "4             0     0     0      0  \n",
            "...         ...   ...   ...    ...  \n",
            "5567          0     0     0      0  \n",
            "5568          0     0     0      0  \n",
            "5569          0     0     0      0  \n",
            "5570          0     0     0      0  \n",
            "5571          0     0     0      0  \n",
            "\n",
            "[5572 rows x 9539 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the sum of word frequencies for each class\n",
        "spam_word_freq = bow_df[df['Class'] == 'spam'].sum()\n",
        "ham_word_freq = bow_df[df['Class'] == 'ham'].sum()\n",
        "\n",
        "# Find the most frequent word in each class\n",
        "most_freq_spam_word = spam_word_freq.idxmax()\n",
        "most_freq_ham_word = ham_word_freq.idxmax()\n",
        "\n",
        "# Print the most frequent words in each class\n",
        "print(f\"most frequent spam word: {most_freq_spam_word}\")\n",
        "print(f\"most frequent non-spam word: {most_freq_ham_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdnZZ6pHtgZW",
        "outputId": "6630bd69-33ed-406f-e6f2-8c2e64186579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent spam word: to\n",
            "most frequent non-spam word: you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, df['Class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict the class labels for the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "accuracy = lr.score(X_test, y_test)\n",
        "\n",
        "# Print the predicted class labels for the testing set\n",
        "print(y_pred)\n",
        "\n",
        "# Print the accuracy of the classifier\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp0pYuwRyOyv",
        "outputId": "17c8e643-1d12-49a5-9a6b-9d438613c0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n",
            "0.9775784753363229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**V. Topic Modelling**"
      ],
      "metadata": {
        "id": "kYFMLnMhgl-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: import needed libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from gensim import corpora, models"
      ],
      "metadata": {
        "id": "OIQst9jugoDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6225bebf-c51b-4bbc-d5cc-8eb4996e9031"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('random_headlines.csv')\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt33eN1LCk30",
        "outputId": "53c1aaff-8546-4f30-a5ac-b50ac4a925e3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 2)\n",
            "   publish_date                          headline_text\n",
            "0      20120305  ute driver hurt in intersection crash\n",
            "1      20081128           6yo dies in cycling accident\n",
            "2      20090325          bumper olive harvest expected\n",
            "3      20100201     replica replaces northernmost sign\n",
            "4      20080225           woods targets perfect season\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VsQ9OaPCpSg",
        "outputId": "6fc0246a-136d-46a0-dacd-9124b5bd824f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   publish_date   20000 non-null  int64 \n",
            " 1   headline_text  20000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 312.6+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for preprocessing\n",
        "def preprocess(text):\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "    # Remove stop words\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Stem\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Apply the preprocessing function to the 'headline_text' column\n",
        "df['stemmed'] = df['headline_text'].apply(preprocess)\n",
        "\n",
        "# Print the output\n",
        "print(df['stemmed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2LsOudCrzE",
        "outputId": "f70977a2-7249-4d88-c063-8ce31145a6ef"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                    [ute, driver, hurt, intersect, crash]\n",
            "1                                  [6yo, die, cycl, accid]\n",
            "2                          [bumper, oliv, harvest, expect]\n",
            "3                    [replica, replac, northernmost, sign]\n",
            "4                          [wood, target, perfect, season]\n",
            "                               ...                        \n",
            "19995               [judg, attack, walkinshaw, run, arrow]\n",
            "19996           [polish, govt, collaps, elect, held, next]\n",
            "19997                              [drum, friday, may, 29]\n",
            "19998            [winterbottom, bathurst, provision, pole]\n",
            "19999    [pull, pork, pawpaw, salad, local, success, st...\n",
            "Name: stemmed, Length: 20000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compute the BOW using Gensim\n",
        "dictionary = corpora.Dictionary(df['stemmed'])\n",
        "\n",
        "bow_corpus = df['stemmed'].apply(dictionary.doc2bow)\n",
        "\n",
        "print(bow_corpus.shape)\n",
        "print(bow_corpus.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgqeZC-qDOLl",
        "outputId": "2a13af1e-3bfc-4dc6-b9c2-8eca5bc9c20d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n",
            "0    [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n",
            "1            [(5, 1), (6, 1), (7, 1), (8, 1)]\n",
            "2         [(9, 1), (10, 1), (11, 1), (12, 1)]\n",
            "3        [(13, 1), (14, 1), (15, 1), (16, 1)]\n",
            "4        [(17, 1), (18, 1), (19, 1), (20, 1)]\n",
            "Name: stemmed, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compute TF-IDF\n",
        "# Convert the bow_corpus Series to a list of tuples\n",
        "bow_corpus_tuples = [doc for doc in df['stemmed'].apply(dictionary.doc2bow)]\n",
        "\n",
        "# Create a TF-IDF model from the list of tuples\n",
        "tfidf = models.TfidfModel(bow_corpus_tuples)\n",
        "\n",
        "# Create a Pandas series of the TF-IDF representation of each document\n",
        "tfidf_corpus = df['stemmed'].apply(lambda x: tfidf[dictionary.doc2bow(x)])\n",
        "\n",
        "# Print the shape and example of the TF-IDF corpus\n",
        "print(tfidf_corpus.shape)\n",
        "print(tfidf_corpus.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWjJX8GDxnt",
        "outputId": "abf4ce6b-425c-4440-fdfc-2be061e4a4eb"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n",
            "0    [(0, 0.30725466582280214), (1, 0.3528943781678...\n",
            "1    [(5, 0.6996935746626014), (6, 0.40368931479963...\n",
            "2    [(9, 0.6052255513921649), (10, 0.3803963291388...\n",
            "3    [(13, 0.6213509318780707), (14, 0.401977885755...\n",
            "4    [(17, 0.5937887452228604), (18, 0.432499245079...\n",
            "Name: stemmed, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compute LSA\n",
        "\n",
        "lsa = models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=5)\n",
        "\n",
        "for i, topic in enumerate(lsa.show_topics()):\n",
        "    print(f\"{topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsUc5H9VEh-l",
        "outputId": "b5571197-4965-4c7f-b555-06c49265f21e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gensim/models/lsimodel.py:963: DeprecationWarning: Please use `csc_matvecs` from the `scipy.sparse` namespace, the `scipy.sparse.sparsetools` namespace is deprecated.\n",
            "  sparsetools.csc_matvecs(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '-0.459*\"man\" + -0.389*\"polic\" + -0.314*\"charg\" + -0.148*\"court\" + -0.146*\"murder\" + -0.131*\"face\" + -0.110*\"crash\" + -0.110*\"miss\" + -0.109*\"new\" + -0.102*\"death\"')\n",
            "(1, '-0.435*\"second\" + -0.408*\"90\" + -0.337*\"abc\" + -0.297*\"news\" + -0.287*\"weather\" + 0.236*\"man\" + -0.236*\"busi\" + -0.180*\"sport\" + 0.163*\"charg\" + -0.104*\"plan\"')\n",
            "(2, '-0.373*\"man\" + -0.272*\"second\" + -0.266*\"charg\" + -0.260*\"90\" + 0.217*\"plan\" + 0.202*\"govt\" + 0.190*\"council\" + 0.175*\"new\" + -0.171*\"abc\" + -0.160*\"weather\"')\n",
            "(3, '-0.766*\"polic\" + 0.246*\"man\" + 0.214*\"charg\" + -0.173*\"investig\" + -0.161*\"probe\" + 0.140*\"court\" + 0.131*\"council\" + 0.130*\"plan\" + 0.104*\"govt\" + 0.103*\"face\"')\n",
            "(4, '-0.716*\"abc\" + 0.436*\"second\" + 0.382*\"90\" + -0.154*\"market\" + -0.137*\"sport\" + -0.126*\"entertain\" + -0.122*\"busi\" + -0.099*\"weather\" + -0.082*\"analysi\" + 0.068*\"council\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Print the 3 or 4 most significant words of each topic\n",
        "\n",
        "for i, topic in enumerate(lsa.show_topics()):\n",
        "    words = topic[1].split(' + ')\n",
        "    print(f\"Topic {i}: {words[:4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d7sqiv9E7dW",
        "outputId": "44028476-2c9f-491c-9ab0-da56ecb37cd4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: ['-0.459*\"man\"', '-0.389*\"polic\"', '-0.314*\"charg\"', '-0.148*\"court\"']\n",
            "Topic 1: ['-0.435*\"second\"', '-0.408*\"90\"', '-0.337*\"abc\"', '-0.297*\"news\"']\n",
            "Topic 2: ['-0.373*\"man\"', '-0.272*\"second\"', '-0.266*\"charg\"', '-0.260*\"90\"']\n",
            "Topic 3: ['-0.766*\"polic\"', '0.246*\"man\"', '0.214*\"charg\"', '-0.173*\"investig\"']\n",
            "Topic 4: ['-0.716*\"abc\"', '0.436*\"second\"', '0.382*\"90\"', '-0.154*\"market\"']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compute LDA\n",
        "lda = models.LdaModel(tfidf_corpus, id2word=dictionary, num_topics=5)\n",
        "\n",
        "# Print the topics and their most frequent words\n",
        "for i, topic in enumerate(lda.show_topics()):\n",
        "    print(f\"{topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qeU-1mbFfv9",
        "outputId": "1e64678a-a029-4462-c486-95da4fc1af23"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.004*\"interview\" + 0.004*\"plan\" + 0.003*\"fund\" + 0.003*\"govt\" + 0.003*\"back\" + 0.002*\"new\" + 0.002*\"tiger\" + 0.002*\"pressur\" + 0.002*\"job\" + 0.002*\"tourism\"')\n",
            "(1, '0.004*\"review\" + 0.004*\"countri\" + 0.003*\"court\" + 0.003*\"accus\" + 0.003*\"win\" + 0.003*\"man\" + 0.003*\"hour\" + 0.003*\"sale\" + 0.003*\"may\" + 0.003*\"hear\"')\n",
            "(2, '0.008*\"polic\" + 0.007*\"man\" + 0.006*\"charg\" + 0.005*\"car\" + 0.004*\"woman\" + 0.004*\"murder\" + 0.004*\"miss\" + 0.004*\"kill\" + 0.004*\"found\" + 0.004*\"crash\"')\n",
            "(3, '0.004*\"market\" + 0.003*\"australian\" + 0.003*\"rate\" + 0.003*\"rise\" + 0.003*\"mine\" + 0.003*\"compani\" + 0.003*\"price\" + 0.003*\"png\" + 0.003*\"interview\" + 0.002*\"act\"')\n",
            "(4, '0.005*\"second\" + 0.004*\"abc\" + 0.004*\"news\" + 0.004*\"weather\" + 0.004*\"coast\" + 0.003*\"90\" + 0.003*\"us\" + 0.003*\"gold\" + 0.003*\"new\" + 0.003*\"road\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: print the most frequent words of each topic\n",
        "for i, topic in enumerate(lda.show_topics()):\n",
        "    words = topic[1].split(' + ')\n",
        "    print(f\"Topic {i}: {words[:4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-c1mMKnFlWV",
        "outputId": "7c19b5f1-45cb-4057-82db-32d6b1624747"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: ['0.004*\"interview\"', '0.004*\"plan\"', '0.003*\"fund\"', '0.003*\"govt\"']\n",
            "Topic 1: ['0.004*\"review\"', '0.004*\"countri\"', '0.003*\"court\"', '0.003*\"accus\"']\n",
            "Topic 2: ['0.008*\"polic\"', '0.007*\"man\"', '0.006*\"charg\"', '0.005*\"car\"']\n",
            "Topic 3: ['0.004*\"market\"', '0.003*\"australian\"', '0.003*\"rate\"', '0.003*\"rise\"']\n",
            "Topic 4: ['0.005*\"second\"', '0.004*\"abc\"', '0.004*\"news\"', '0.004*\"weather\"']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim \n",
        "\n",
        "# # Create the LDA visualization\n",
        "# lda_display = pyLDAvis.gensim.prepare(lda, tfidf_corpus, dictionary, sort_topics=False)\n",
        "\n",
        "# # Launch the visualization\n",
        "# pyLDAvis.display(lda_display)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klQBCAuAKE-J",
        "outputId": "fc548d3e-cff6-485f-e74f-5390ed8609f8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VI. Named Entity Recognition**"
      ],
      "metadata": {
        "id": "okm_AC7RgoU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Imports\n",
        "import spacy\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "dJ4Hkpo5gqfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e242e84a-6daa-4942-d3d1-cb9b1c2a8714"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : load file and have a look at it\n",
        "with open('ada_lovelace.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "_VVD7nUASyx0",
        "outputId": "7266e2c1-2f59-4189-8a1f-493224ba1104"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Augusta Ada King, Countess of Lovelace (née Byron; 10 December 1815 – 27 November 1852) was an English mathematician and writer, chiefly known for her work on Charles Babbage\\'s proposed mechanical general-purpose computer, the Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation, and published the first algorithm intended to be carried out by such a machine. As a result, she is sometimes regarded as the first to recognise the full potential of a \"computing machine\" and one of the first computer programmers. \\n\\nLovelace became close friends with her tutor Mary Somerville, who introduced her to Charles Babbage in 1833. She had a strong respect and affection for Somerville, and they corresponded for many years. Other acquaintances included the scientists Andrew Crosse, Sir David Brewster, Charles Wheatstone, Michael Faraday and the author Charles Dickens.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Named Entities Recognition\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-u_bHIiS_LD",
        "outputId": "e9e70aa3-0fc6-4478-a1a2-ddb31fdcc438"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augusta Ada King PERSON\n",
            "Countess PERSON\n",
            "Lovelace PERSON\n",
            "Byron ORG\n",
            "10 December 1815 DATE\n",
            "27 November 1852 DATE\n",
            "English LANGUAGE\n",
            "Charles Babbage's ORG\n",
            "the Analytical Engine ORG\n",
            "first ORDINAL\n",
            "first ORDINAL\n",
            "first ORDINAL\n",
            "one CARDINAL\n",
            "first ORDINAL\n",
            "Lovelace PERSON\n",
            "Mary Somerville PERSON\n",
            "Charles Babbage PERSON\n",
            "1833 DATE\n",
            "Somerville GPE\n",
            "many years DATE\n",
            "Andrew Crosse PERSON\n",
            "David Brewster PERSON\n",
            "Charles Wheatstone PERSON\n",
            "Michael Faraday PERSON\n",
            "Charles Dickens PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : NER visualization\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "_iB2th-QTNbs",
        "outputId": "5ed63cff-aff9-417b-bd9d-07231d4ed7de"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Augusta Ada King\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Countess\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lovelace\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " (née \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Byron\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "; \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    10 December 1815\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " – \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    27 November 1852\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ") was an \n",
              "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    English\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
              "</mark>\n",
              " mathematician and writer, chiefly known for her work on \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Charles Babbage's\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " proposed mechanical general-purpose computer, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Analytical Engine\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". She was the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " to recognise that the machine had applications beyond pure calculation, and published the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " algorithm intended to be carried out by such a machine. As a result, she is sometimes regarded as the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " to recognise the full potential of a &quot;computing machine&quot; and \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    one\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " computer programmers. </br></br>\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lovelace\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " became close friends with her tutor \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mary Somerville\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who introduced her to \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Charles Babbage\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1833\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". She had a strong respect and affection for \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Somerville\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", and they corresponded for \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    many years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Other acquaintances included the scientists \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Andrew Crosse\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", Sir \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    David Brewster\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Charles Wheatstone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Michael Faraday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and the author \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Charles Dickens\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : `replace_name_by_redacted`\n",
        "def replace_name_by_redacted(token):\n",
        "    if token.ent_type_ == 'PERSON':\n",
        "      return '[REDACTED]'\n",
        "    else:\n",
        "      return token.text\n",
        "\n",
        "def make_doc_GDPR_compliant(doc):\n",
        "    return ' '.join([replace_name_by_redacted(token) for token in doc])\n",
        "\n",
        "compliant_text = make_doc_GDPR_compliant(doc)\n",
        "compliant_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "gvnNn6BeUQhD",
        "outputId": "783d9ea6-9820-4a65-c422-354de23f8071"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[REDACTED] [REDACTED] [REDACTED] , [REDACTED] of [REDACTED] ( née Byron ; 10 December 1815 – 27 November 1852 ) was an English mathematician and writer , chiefly known for her work on Charles Babbage \\'s proposed mechanical general - purpose computer , the Analytical Engine . She was the first to recognise that the machine had applications beyond pure calculation , and published the first algorithm intended to be carried out by such a machine . As a result , she is sometimes regarded as the first to recognise the full potential of a \" computing machine \" and one of the first computer programmers . \\n\\n [REDACTED] became close friends with her tutor [REDACTED] [REDACTED] , who introduced her to [REDACTED] [REDACTED] in 1833 . She had a strong respect and affection for Somerville , and they corresponded for many years . Other acquaintances included the scientists [REDACTED] [REDACTED] , Sir [REDACTED] [REDACTED] , [REDACTED] [REDACTED] , [REDACTED] [REDACTED] and the author [REDACTED] [REDACTED] .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  function make_doc_GDPR_compliant:\n",
        "def make_doc_GDPR_compliant(doc):\n",
        "    return ' '.join([replace_name_by_redacted(token) for token in doc])\n",
        "\n",
        "compliant_text = make_doc_GDPR_compliant(doc)\n",
        "compliant_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njONKD9hVwF0",
        "outputId": "36eac2ea-5823-4ff7-f244-1273546bddd0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VII. Exercise**"
      ],
      "metadata": {
        "id": "IFIsVPcTgqyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. By using the job market data, finish the following task to analyze the top important keywords\n",
        "for IT sector.\n",
        "+ Filter the jobs for IT sector only.\n",
        "+ Put the description of all jobs into a list.\n",
        "+ Use scikit-learn to get top 20 important keywords.\n",
        "+ Choose one favourite keyword and perform information retrieval with scikit-learn."
      ],
      "metadata": {
        "id": "zt1G--2BdMpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Load the job-market.csv file into a pandas DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/job-market.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWv_hzgZdOAG",
        "outputId": "17128795-6df3-4487-fac1-154e1fb4a617"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the data.\n",
        "data.dropna(inplace=True)\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Fix column datatypes.\n",
        "import re\n",
        "\n",
        "# Define a function to clean a string\n",
        "def clean_string(text):\n",
        "    if text:\n",
        "        # Remove HTML tags\n",
        "        clean = re.compile('<.*?>')\n",
        "        text = re.sub(clean, '', text)\n",
        "        \n",
        "        # Replace '&nbsp;' and '\\n *&nbsp;' with a space\n",
        "        text = re.sub(r'(&nbsp;|\\n *&nbsp;)', ' ', text)\n",
        "        \n",
        "        # Remove unwanted characters\n",
        "        text = re.sub(r'\\n *|\\*', '', text)\n",
        "        \n",
        "        return text if text else None\n",
        "\n",
        "data['Id'] = data['Id'].astype(int)\n",
        "data['LowestSalary'] = data['LowestSalary'].astype(int)\n",
        "data['HighestSalary'] = data['HighestSalary'].astype(int)\n",
        "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "data['LowestSalary'] = pd.to_numeric(data['LowestSalary'], errors='coerce')\n",
        "data['HighestSalary'] = pd.to_numeric(data['HighestSalary'], errors='coerce')\n",
        "data['FullDescription'] = data['FullDescription'].apply(clean_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu8UVmqbjnwo",
        "outputId": "7436994f-fe2f-40a1-8de4-7a5b6d096ac1"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the jobs for IT sector only.\n",
        "it_df = data[data['Classification'] == 'Information & Communication Technology']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElMDm6oQiDQA",
        "outputId": "76ecd25f-1ef2-4094-bb03-671cdf0cf32c"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the description of all jobs into a list.\n",
        "descriptions = it_df['FullDescription'].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEuZe4EhiIPh",
        "outputId": "e7d46c76-1aa8-4230-a929-473bf01afd89"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any NaN values from the descriptions list\n",
        "descriptions = [desc for desc in descriptions if isinstance(desc, str)]\n",
        "\n",
        "# Use scikit-learn to get top 20 important keywords\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(descriptions)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
        "feature_names = count_vect.get_feature_names_out().tolist() # convert to list\n",
        "tfidf_scores = X_tfidf.toarray().sum(axis=0)\n",
        "top_keywords_idx = tfidf_scores.argsort()[::-1][:20]\n",
        "top_keywords = [feature_names[i] for i in top_keywords_idx]\n",
        "print(\"Top 20 important keywords:\", top_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBq1rTgJiOs6",
        "outputId": "92fdc9b5-1416-45a5-bbfe-c0637f72943e"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 important keywords: ['and', 'to', 'the', 'of', 'in', 'with', 'you', 'for', 'experience', 'be', 'will', 'our', 'is', 'we', 'business', 'on', 'team', 'this', 'are', 'or']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "favourite_keyword = \"python\"\n",
        "keyword_idx = feature_names.index(favourite_keyword)\n",
        "job_indices = X_tfidf[:, keyword_idx].nonzero()[0]\n",
        "relevant_jobs = it_df.iloc[job_indices]['FullDescription']\n",
        "print(\"Number of relevant jobs:\",len(relevant_jobs))\n",
        "print(\"Sample relevant job descriptions:\\n\", relevant_jobs.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kIFx-Kfiazq",
        "outputId": "f6b65cb9-93ed-4314-9db5-5050387d7200"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of relevant jobs: 13\n",
            "Sample relevant job descriptions:\n",
            " 1135    Hi Everyone,Our company is seeking an energeti...\n",
            "1223    About Us: Infosys is a global leader in consul...\n",
            "1265    iOS Developer We are looking for a passionate ...\n",
            "1446    The Client:Located in one of Melbourne's most ...\n",
            "1555    JOB DESCRIPTION• Consult with BSFI customers o...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Implement a method capable of extracting n-grams from a given sequence object (e.g., string\n",
        "and list). Utilize this feature to produce word tri-grams, letter tri-grams based on the sentence \"I\n",
        "like deadline and want to immerse myself in deadline.\"\n"
      ],
      "metadata": {
        "id": "YXqGu1J9dBzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ngrams(sequence, n):\n",
        "    ngrams = []\n",
        "    for i in range(len(sequence)-n+1):\n",
        "        ngram = sequence[i:i+n]\n",
        "        ngrams.append(ngram)\n",
        "    return ngrams\n",
        "\n",
        "sentence = \"I like deadline and want to immerse myself in deadline.\"\n",
        "words = sentence.split()\n",
        "word_trigrams = extract_ngrams(words, 3)\n",
        "print(word_trigrams)\n",
        "\n",
        "letters = sentence.replace(\" \", \"\")\n",
        "letter_trigrams = extract_ngrams(letters, 3)\n",
        "print(letter_trigrams)"
      ],
      "metadata": {
        "id": "MZ1BlwtEgsUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14085bc3-aa47-40c3-a80d-d8018e7e0bbf"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['I', 'like', 'deadline'], ['like', 'deadline', 'and'], ['deadline', 'and', 'want'], ['and', 'want', 'to'], ['want', 'to', 'immerse'], ['to', 'immerse', 'myself'], ['immerse', 'myself', 'in'], ['myself', 'in', 'deadline.']]\n",
            "['Ili', 'lik', 'ike', 'ked', 'ede', 'dea', 'ead', 'adl', 'dli', 'lin', 'ine', 'nea', 'ean', 'and', 'ndw', 'dwa', 'wan', 'ant', 'ntt', 'tto', 'toi', 'oim', 'imm', 'mme', 'mer', 'ers', 'rse', 'sem', 'emy', 'mys', 'yse', 'sel', 'elf', 'lfi', 'fin', 'ind', 'nde', 'dea', 'ead', 'adl', 'dli', 'lin', 'ine', 'ne.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Construct a program that satisfies these criteria in line with them: You will be provided with a string of words that are separated by a certain amount of space. Every time one of the following words occurs in this order: If the phrase can be written with no more than four letters, then its original form should be maintained. In any other circumstance, the opening letter and the final letter should both be kept the same. Switch out some of the letters for others and rearrange them in a chaotic sequence (in the middle of the word) Using a statement such as \"I couldn't believe that I could completely understand what I was reading: the astounding power of the human mind\" as an example, describe the results by providing a statement such as \"I couldn't believe that I could truly comprehend what I was reading.\""
      ],
      "metadata": {
        "id": "lDXz6ndJd29O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "# Define the list of trigger words\n",
        "trigger_words = [\"believe\", \"completely\", \"understand\", \"astounding\", \"power\", \"human\", \"mind\"]\n",
        "\n",
        "# Define a function to process each word in the input string\n",
        "def process_word(word):\n",
        "    if word.lower() in trigger_words:\n",
        "        if len(word) <= 4:\n",
        "            return word\n",
        "        else:\n",
        "            first_letter = word[0]\n",
        "            last_letter = word[-1]\n",
        "            middle_letters = list(word[1:-1])\n",
        "            random.shuffle(middle_letters)\n",
        "            return first_letter + ''.join(middle_letters) + last_letter\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "# Define the input string\n",
        "input_string = \"I couldn't believe that I could completely understand what I was reading: the astounding power of the human mind\"\n",
        "\n",
        "# Split the input string into words\n",
        "words = re.findall(r'\\b\\w+\\b', input_string)\n",
        "\n",
        "# Process each word using the process_word function\n",
        "processed_words = [process_word(word) for word in words]\n",
        "\n",
        "# Join the processed words back into a string\n",
        "output_string = ' '.join(processed_words)\n",
        "\n",
        "# Print the output string\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KYshsEccrpY",
        "outputId": "ac9717a0-ef9b-45a6-e492-5e9a404b7213"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I couldn t bvielee that I could cpmtolleey unaestnrdd what I was reading the adntsinoug power of the huamn mind\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The zip file alice.zip includes the text file alice.txt containing Lewis Carroll's book Alice's\n",
        "Adventures in Wonderland, which is available on Project Gutenberg. Apply a part-of-speech\n",
        "(POS) tagger to the text file, then save the output to a separate file. Implement programmes that\n",
        "read the results of POS tagging and carry out the tasks."
      ],
      "metadata": {
        "id": "J5w_Uceoen--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load the text file\n",
        "with open('alice.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# Process each sentence and tag the parts of speech\n",
        "pos_sentences = []\n",
        "for sentence in sentences:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    pos_sentences.append(pos_tags)\n",
        "\n",
        "# Save the POS tagged sentences to a separate file\n",
        "with open('alice_pos.txt', 'w') as f:\n",
        "    for sentence in pos_sentences:\n",
        "        f.write(str(sentence))\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl4FkS_edkID",
        "outputId": "08734ef8-e0e9-4843-b81a-fd61ec2432c0"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the POS tagged file\n",
        "with open('alice_pos.txt', 'r') as f:\n",
        "    pos_text = f.read()\n",
        "\n",
        "# Split the text into sentences\n",
        "pos_sentences = pos_text.split('\\n')\n",
        "\n",
        "# Count the number of nouns in the text\n",
        "noun_count = 0\n",
        "for sentence in pos_sentences:\n",
        "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
        "        if pos.startswith('N'):\n",
        "            noun_count += 1\n",
        "\n",
        "print(\"Number of nouns in the text:\", noun_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4fIz5u7e5JU",
        "outputId": "0f619c9f-7e9b-4071-a932-277d09bfcc99"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nouns in the text: 33224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the POS tagged file\n",
        "with open('alice_pos.txt', 'r') as f:\n",
        "    pos_text = f.read()\n",
        "\n",
        "# Split the text into sentences\n",
        "pos_sentences = pos_text.split('\\n')\n",
        "\n",
        "# Extract all the adjectives in the text\n",
        "adjectives = set()\n",
        "for sentence in pos_sentences:\n",
        "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
        "        if pos.startswith('JJ'):\n",
        "            adjectives.add(word)\n",
        "\n",
        "# Save the adjectives to a separate file\n",
        "with open('alice_adjectives.txt', 'w') as f:\n",
        "    for adj in adjectives:\n",
        "        f.write(adj)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEYSCZkXe9AB",
        "outputId": "dc28f9b6-9f89-420d-94d8-9e799d19982a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the POS tagged file\n",
        "with open('alice_pos.txt', 'r') as f:\n",
        "    pos_text = f.read()\n",
        "\n",
        "# Split the text into sentences\n",
        "pos_sentences = pos_text.split('\\n')\n",
        "\n",
        "# Replace all the verbs in the text with their past tense forms\n",
        "new_sentences = []\n",
        "for sentence in pos_sentences:\n",
        "    new_tokens = []\n",
        "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
        "        if pos.startswith('V'):\n",
        "            new_word = nltk.stem.WordNetLemmatizer().lemmatize(word, 'v')\n",
        "            new_word = nltk.corpus.wordnet.morphy(new_word, nltk.corpus.wordnet.VERB)\n",
        "            if new_word:\n",
        "                new_tokens.append(new_word)\n",
        "            else:\n",
        "                new_tokens.append(word)\n",
        "        else:\n",
        "            new_tokens.append(word)\n",
        "    new_sentence = ' '.join(new_tokens)\n",
        "\n",
        "    new_sentences.append(new_sentence)\n",
        "\n",
        "# Save the modified sentences to a separate file\n",
        "with open('alice_past_tense.txt', 'w') as f:\n",
        "    for sentence in new_sentences:\n",
        "        f.write(sentence)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysbk2RCXfEcI",
        "outputId": "9cc4590e-5cc7-453d-ac52-3d3b8260070d"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#END: Best luck for you, thank you!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-LWp2afKg-",
        "outputId": "66bd62b5-9616-4196-d53f-fbb90e7f3073"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}